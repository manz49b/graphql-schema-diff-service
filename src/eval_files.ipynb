{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "- This notebook allows a user to explore evaluations of tested prompts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11, 24)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>example_no</th>\n",
       "      <th>prompt_version</th>\n",
       "      <th>llm_bleu_score</th>\n",
       "      <th>llm_rouge_score</th>\n",
       "      <th>llm_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>example</td>\n",
       "      <td>7</td>\n",
       "      <td>0.449965</td>\n",
       "      <td>{'rouge-1': {'f': 0.6071428521444515, 'p': 0.6...</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>example</td>\n",
       "      <td>6</td>\n",
       "      <td>0.432629</td>\n",
       "      <td>{'rouge-1': {'f': 0.6140350827192983, 'p': 0.6...</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>example</td>\n",
       "      <td>4</td>\n",
       "      <td>0.306604</td>\n",
       "      <td>{'rouge-1': {'f': 0.591304342826465, 'p': 0.58...</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>example</td>\n",
       "      <td>5</td>\n",
       "      <td>0.317677</td>\n",
       "      <td>{'rouge-1': {'f': 0.5614035037719299, 'p': 0.5...</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>example</td>\n",
       "      <td>1</td>\n",
       "      <td>0.453636</td>\n",
       "      <td>{'rouge-1': {'f': 0.5607476585728012, 'p': 0.6...</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>example</td>\n",
       "      <td>3</td>\n",
       "      <td>0.364264</td>\n",
       "      <td>{'rouge-1': {'f': 0.5840707914605686, 'p': 0.5...</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>example</td>\n",
       "      <td>2</td>\n",
       "      <td>0.389698</td>\n",
       "      <td>{'rouge-1': {'f': 0.5794392473578479, 'p': 0.6...</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>example</td>\n",
       "      <td>8</td>\n",
       "      <td>0.383626</td>\n",
       "      <td>{'rouge-1': {'f': 0.5739130384786391, 'p': 0.5...</td>\n",
       "      <td>0.823529</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   example_no  prompt_version  llm_bleu_score  \\\n",
       "1     example               7        0.449965   \n",
       "3     example               6        0.432629   \n",
       "4     example               4        0.306604   \n",
       "5     example               5        0.317677   \n",
       "7     example               1        0.453636   \n",
       "9     example               3        0.364264   \n",
       "10    example               2        0.389698   \n",
       "8     example               8        0.383626   \n",
       "\n",
       "                                      llm_rouge_score    llm_f1  \n",
       "1   {'rouge-1': {'f': 0.6071428521444515, 'p': 0.6...  0.750000  \n",
       "3   {'rouge-1': {'f': 0.6140350827192983, 'p': 0.6...  0.750000  \n",
       "4   {'rouge-1': {'f': 0.591304342826465, 'p': 0.58...  0.750000  \n",
       "5   {'rouge-1': {'f': 0.5614035037719299, 'p': 0.5...  0.750000  \n",
       "7   {'rouge-1': {'f': 0.5607476585728012, 'p': 0.6...  0.750000  \n",
       "9   {'rouge-1': {'f': 0.5840707914605686, 'p': 0.5...  0.750000  \n",
       "10  {'rouge-1': {'f': 0.5794392473578479, 'p': 0.6...  0.750000  \n",
       "8   {'rouge-1': {'f': 0.5739130384786391, 'p': 0.5...  0.823529  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "from glob import glob\n",
    "from base import DATA_PATH\n",
    "\n",
    "EVAL_DIR = '../data/evaluations'\n",
    "files = glob(os.path.join(EVAL_DIR, '*.parquet'))\n",
    "dfs = [pd.read_parquet(file) for file in files]\n",
    "merged = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "print(merged.shape)\n",
    "cols = ['example_no','prompt_version','llm_bleu_score','llm_rouge_score','llm_f1']\n",
    "example_1 = merged[merged.example_no=='example']\n",
    "# example_2 = merged[merged.example_no=='example-1']\n",
    "example_1[cols].sort_values(by='llm_f1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review\n",
    "- Taking a look at the LLM response with the highest F1 score.\n",
    "## Expected output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "example='example'\n",
    "output_path = (f'{DATA_PATH}/output-{example}.txt')\n",
    "with open(output_path, 'r') as file:\n",
    "    expected_output = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'changes': [{'type': 'Query',\n",
       "   'field': 'getWeather',\n",
       "   'change': \"Renamed input parameter 'location' to 'city'\",\n",
       "   'breaking': True,\n",
       "   'release_note': 'The input parameter for `getWeather` has been renamed from `location` to `city`. This is a breaking change, so make sure to update any queries that use `location` to `city`.'},\n",
       "  {'type': 'Weather',\n",
       "   'field': 'visibility',\n",
       "   'change': \"Added new Int field 'visibility'\",\n",
       "   'breaking': False,\n",
       "   'release_note': \"We've added a new `visibility` field to the `Weather` type. You can now get visibility information in your weather queries without modifying existing ones. This is a non-breaking change.\"}],\n",
       " 'release_notes': {'summary': 'This release introduces a breaking change with the renaming of the `location` parameter to `city` in the `getWeather` query, and a non-breaking enhancement with the addition of a new `visibility` field in the `Weather` type.'}}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expected_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'changes': [{'type': 'Query',\n",
       "   'field': 'getWeather',\n",
       "   'change': \"Parameter name changed from 'location' to 'city'\",\n",
       "   'breaking': True,\n",
       "   'release_note': 'The parameter name in `getWeather` query has been changed from `location` to `city`. This is a breaking change - existing queries using the `location` parameter will need to be updated to use `city` instead.'},\n",
       "  {'type': 'Weather',\n",
       "   'field': 'visibility',\n",
       "   'change': \"Added new Int field 'visibility'\",\n",
       "   'breaking': False,\n",
       "   'release_note': 'A new nullable field `visibility` has been added to the `Weather` type. This is a non-breaking change that provides additional weather information.'}],\n",
       " 'release_notes': {'summary': 'This release includes one breaking change to the `getWeather` query parameter (renamed from `location` to `city`) and adds a new non-breaking `visibility` field to the `Weather` type. Clients must update their existing queries that use the `getWeather` query to use the new parameter name `city`. The new `visibility` field is optional and can be used to access additional weather information.'}}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(example_1[example_1.prompt_version==8].llm_change_report.values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Claude review\n",
    "- How does self model evaluation differ, what does Claude believe is the best?\n",
    "\n",
    "Explanation of scoring:\n",
    "- All responses captured the core changes correctly (parameter rename and new visibility field)\n",
    "- Minor variations in wording were overlooked as requested\n",
    "- Small deductions were made for:\n",
    "  * Slight differences in release note phrasing\n",
    "  * Varying levels of detail in the summaries\n",
    "  * Minor differences in how the changes were described\n",
    "- Response 8 got a slightly lower score due to having a more concise summary that missed some details present in the expected output\n",
    "- None had major errors or missing information, hence the generally high scores\n",
    "- Perfect matches weren't required for full credit, as requested to be lenient with minor differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debug: Sending prompt to Claude (length: 9071): You are a Developer that is reviewing code changes to schemas. Given the expected output:\n",
      "{'changes': [{'type': 'Query', 'field': 'getWeather', 'change': \"Renamed input parameter 'location' to 'city'\"...\n",
      "Debug: Successfully received response from Claude.\n"
     ]
    }
   ],
   "source": [
    "from claude import create_message\n",
    "\n",
    "prompt = f\"\"\"You are a Developer that is reviewing code changes to schemas. Given the expected output:\n",
    "{expected_output}\n",
    "\n",
    "Score each of the below responses out of 100% based on how well they match the expected output.\n",
    "Be lenient with minor differences in punctuation, word order, capitalization, and spacing.\n",
    "{'response: '.join(example_1.llm_change_report.values)}\n",
    "\n",
    "Return your response in JSON format with the following structure:\n",
    "{{\n",
    "    \"accuracy\": 78%,\n",
    "    \"accuracy\": 52%,\n",
    "}}\n",
    "\"\"\"\n",
    "response = create_message(prompt, 4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values(['95%', '92%', '90%', '93%', '94%', '91%', '92%', '88%'])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_json(res):\n",
    "    s = res.find(\"{\")\n",
    "    e = res.rfind(\"}\") + 1\n",
    "    return json.loads(res[s:e])\n",
    "\n",
    "res_dict = extract_json(response[0].text)\n",
    "res_dict.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>example_no</th>\n",
       "      <th>prompt_version</th>\n",
       "      <th>llm_bleu_score</th>\n",
       "      <th>llm_rouge_score</th>\n",
       "      <th>llm_f1</th>\n",
       "      <th>llm_self_eval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>example</td>\n",
       "      <td>2</td>\n",
       "      <td>0.389698</td>\n",
       "      <td>{'rouge-1': {'f': 0.5794392473578479, 'p': 0.6...</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>88%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>example</td>\n",
       "      <td>4</td>\n",
       "      <td>0.306604</td>\n",
       "      <td>{'rouge-1': {'f': 0.591304342826465, 'p': 0.58...</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>90%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>example</td>\n",
       "      <td>8</td>\n",
       "      <td>0.383626</td>\n",
       "      <td>{'rouge-1': {'f': 0.5739130384786391, 'p': 0.5...</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>91%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>example</td>\n",
       "      <td>6</td>\n",
       "      <td>0.432629</td>\n",
       "      <td>{'rouge-1': {'f': 0.6140350827192983, 'p': 0.6...</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>92%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>example</td>\n",
       "      <td>3</td>\n",
       "      <td>0.364264</td>\n",
       "      <td>{'rouge-1': {'f': 0.5840707914605686, 'p': 0.5...</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>92%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>example</td>\n",
       "      <td>5</td>\n",
       "      <td>0.317677</td>\n",
       "      <td>{'rouge-1': {'f': 0.5614035037719299, 'p': 0.5...</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>93%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>example</td>\n",
       "      <td>1</td>\n",
       "      <td>0.453636</td>\n",
       "      <td>{'rouge-1': {'f': 0.5607476585728012, 'p': 0.6...</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>94%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>example</td>\n",
       "      <td>7</td>\n",
       "      <td>0.449965</td>\n",
       "      <td>{'rouge-1': {'f': 0.6071428521444515, 'p': 0.6...</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>95%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   example_no  prompt_version  llm_bleu_score  \\\n",
       "10    example               2        0.389698   \n",
       "4     example               4        0.306604   \n",
       "8     example               8        0.383626   \n",
       "3     example               6        0.432629   \n",
       "9     example               3        0.364264   \n",
       "5     example               5        0.317677   \n",
       "7     example               1        0.453636   \n",
       "1     example               7        0.449965   \n",
       "\n",
       "                                      llm_rouge_score    llm_f1 llm_self_eval  \n",
       "10  {'rouge-1': {'f': 0.5794392473578479, 'p': 0.6...  0.750000           88%  \n",
       "4   {'rouge-1': {'f': 0.591304342826465, 'p': 0.58...  0.750000           90%  \n",
       "8   {'rouge-1': {'f': 0.5739130384786391, 'p': 0.5...  0.823529           91%  \n",
       "3   {'rouge-1': {'f': 0.6140350827192983, 'p': 0.6...  0.750000           92%  \n",
       "9   {'rouge-1': {'f': 0.5840707914605686, 'p': 0.5...  0.750000           92%  \n",
       "5   {'rouge-1': {'f': 0.5614035037719299, 'p': 0.5...  0.750000           93%  \n",
       "7   {'rouge-1': {'f': 0.5607476585728012, 'p': 0.6...  0.750000           94%  \n",
       "1   {'rouge-1': {'f': 0.6071428521444515, 'p': 0.6...  0.750000           95%  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_1['llm_self_eval'] = res_dict.values()\n",
    "cols = ['example_no','prompt_version','llm_bleu_score','llm_rouge_score','llm_f1','llm_self_eval']\n",
    "example_1[cols].sort_values(by='llm_self_eval')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'changes': [{'type': 'Query',\n",
       "   'field': 'getWeather',\n",
       "   'change': \"Renamed input parameter 'location' to 'city'\",\n",
       "   'breaking': True,\n",
       "   'release_note': 'The input parameter for `getWeather` has been renamed from `location` to `city`. This is a breaking change, so make sure to update any queries that use `location` to `city`.'},\n",
       "  {'type': 'Weather',\n",
       "   'field': 'visibility',\n",
       "   'change': \"Added new Int field 'visibility'\",\n",
       "   'breaking': False,\n",
       "   'release_note': \"We've added a new `visibility` field to the `Weather` type. You can now get visibility information in your weather queries without modifying existing ones. This is a non-breaking change.\"}],\n",
       " 'release_notes': {'summary': 'This release introduces a breaking change with the renaming of the `location` parameter to `city` in the `getWeather` query, and a non-breaking enhancement with the addition of a new `visibility` field in the `Weather` type.'}}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expected_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'changes': [{'type': 'Query',\n",
       "   'field': 'getWeather',\n",
       "   'change': \"Parameter 'location' renamed to 'city'\",\n",
       "   'breaking': True,\n",
       "   'release_note': 'The parameter name for `getWeather` query has been changed from `location` to `city`. This is a breaking change and requires clients to update their queries to use the new parameter name.'},\n",
       "  {'type': 'Weather',\n",
       "   'field': 'visibility',\n",
       "   'change': \"Added new Int field 'visibility'\",\n",
       "   'breaking': False,\n",
       "   'release_note': 'A new field `visibility` has been added to the `Weather` type. This optional field provides visibility information. This is a non-breaking change.'}],\n",
       " 'release_notes': {'summary': 'This release includes one breaking change to the `getWeather` query, where the input parameter has been renamed from `location` to `city`. Additionally, a non-breaking change adds a new `visibility` field to the `Weather` type. Clients must update their queries to use the new parameter name `city`, but can optionally start using the new `visibility` field.'}}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(example_1[example_1.prompt_version==7].llm_change_report.values[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graphql-schema-diff-service",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
