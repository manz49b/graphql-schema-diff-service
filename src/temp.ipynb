{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"changes\": [\n",
      "    {\n",
      "      \"type\": \"Query\",\n",
      "      \"field\": \"getWeather\",\n",
      "      \"change\": \"Renamed input parameter 'location' to 'city'\",\n",
      "      \"breaking\": true,\n",
      "      \"release_note\": \"The input parameter for `getWeather` has been renamed from `location` to `city`. This is a breaking change, so make sure to update any queries that use `location` to `city`.\"\n",
      "    },\n",
      "    {\n",
      "      \"type\": \"Weather\",\n",
      "      \"field\": \"visibility\",\n",
      "      \"change\": \"Added new scalar field 'visibility'\",\n",
      "      \"breaking\": false,\n",
      "      \"release_note\": \"We've added a new `visibility` field to the `Weather` type. You can now get additional information without modifying existing queries. This is a non-breaking change.\"\n",
      "    }\n",
      "  ],\n",
      "  \"release_notes\": {\n",
      "    \"summary\": \"This release introduces breaking changes including: Renamed input parameter 'location' to 'city'; non-breaking enhancements: Added new scalar field 'visibility'\"\n",
      "  }\n",
      "}\n",
      "{\n",
      "  \"changes\": [\n",
      "    {\n",
      "      \"type\": \"Query\",\n",
      "      \"field\": \"getWeather\",\n",
      "      \"change\": \"Parameter 'location' renamed to 'city'\",\n",
      "      \"breaking\": true,\n",
      "      \"release_note\": \"The parameter name in `getWeather` query has been changed from `location` to `city`. This is a breaking change as existing queries using `location` parameter will fail.\"\n",
      "    },\n",
      "    {\n",
      "      \"type\": \"Weather\",\n",
      "      \"field\": \"visibility\",\n",
      "      \"change\": \"Added new Int field 'visibility'\",\n",
      "      \"breaking\": false,\n",
      "      \"release_note\": \"A new nullable field `visibility` has been added to the `Weather` type. This addition allows clients to retrieve visibility information. This is a non-breaking change.\"\n",
      "    }\n",
      "  ],\n",
      "  \"release_notes\": {\n",
      "    \"summary\": \"This release includes one breaking change in the `getWeather` query where the parameter name has been updated from `location` to `city`. Additionally, a new non-breaking change introduces the `visibility` field to the `Weather` type for enhanced weather information.\"\n",
      "  }\n",
      "}\n",
      "LLM Scoring:\n",
      "BLEU Score: 0.0000\n",
      "ROUGE Score: {'rouge-1': {'r': 0.7307692307692307, 'p': 0.5757575757575758, 'f': 0.6440677916805516}, 'rouge-2': {'r': 0.28125, 'p': 0.24324324324324326, 'f': 0.26086956024364644}, 'rouge-l': {'r': 0.5384615384615384, 'p': 0.42424242424242425, 'f': 0.4745762662568228}}\n",
      "Exact Match: False\n",
      "Python Method Scoring:\n",
      "BLEU Score: 0.0000\n",
      "ROUGE Score: {'rouge-1': {'r': 0.34615384615384615, 'p': 0.47368421052631576, 'f': 0.39999999512098766}, 'rouge-2': {'r': 0.0625, 'p': 0.1111111111111111, 'f': 0.07999999539200027}, 'rouge-l': {'r': 0.34615384615384615, 'p': 0.47368421052631576, 'f': 0.39999999512098766}}\n",
      "Exact Match: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/mambaforge/base/envs/graphql-schema-diff-service/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "from schema_parser import SchemaParser\n",
    "from schema_diff import SchemaDiff, json\n",
    "from prompt import get_prompt\n",
    "from claude import create_message\n",
    "from json_tools import safe_load_json\n",
    "from eval import evaluate_response, f1_results, ab_testing, rate_coherence, expert_rubric\n",
    "from base import DATA_PATH\n",
    "\n",
    "examples = [\"example\",\"example-1\"]\n",
    "# Just test one example for now\n",
    "example = examples[0]\n",
    "\n",
    "schema_v1_parser = SchemaParser(f'{DATA_PATH}/schema-1-{example}.txt')\n",
    "schema_v1 = schema_v1_parser.parse()\n",
    "\n",
    "schema_v2_parser = SchemaParser(f'{DATA_PATH}/schema-2-{example}.txt')\n",
    "schema_v2 = schema_v2_parser.parse()\n",
    "\n",
    "output_path = (f'{DATA_PATH}/output-{example}.txt')\n",
    "with open(output_path, 'r') as file:\n",
    "    expected_output = json.load(file)\n",
    "    \n",
    "schema_diff = SchemaDiff(schema_v1, schema_v2)\n",
    "python_change_report = schema_diff.detect_changes()\n",
    "print(json.dumps(python_change_report, indent=2))\n",
    "\n",
    "prompt = get_prompt(schema_v1, schema_v2)\n",
    "response = create_message(prompt, 2048)\n",
    "llm_change_report = safe_load_json(response[0].text)\n",
    "print(json.dumps(llm_change_report, indent=2))\n",
    "\n",
    "# Model eval\n",
    "print(\"LLM Scoring:\")\n",
    "evaluate_response(expected_output, llm_change_report)\n",
    "f1_results(llm_change_report, expected_output)\n",
    "\n",
    "print(\"Python Method Scoring:\")\n",
    "evaluate_response(expected_output, python_change_report)\n",
    "f1_results(python_change_report, expected_output)\n",
    "\n",
    "# DUMMY DATA - below should be replaced with actual user feedback/testing\n",
    "# Running A/B testing\n",
    "llm_pref, python_pref = ab_testing(llm_change_report, python_change_report)\n",
    "print(f\"LLM Preference: {llm_pref:.2f}%\")\n",
    "print(f\"Python Preference: {python_pref:.2f}%\")\n",
    "\n",
    "# Applying Likert scale to responses\n",
    "llm_coherence_score, llm_ratings = rate_coherence(llm_change_report)\n",
    "python_coherence_score, python_ratings = rate_coherence(python_change_report)\n",
    "\n",
    "print(f\"LLM Coherence Score: {llm_coherence_score}\")\n",
    "print(f\"Python Coherence Score: {python_coherence_score}\")\n",
    "print(\"LLM Detailed Ratings:\", llm_ratings)\n",
    "print(\"Python Detailed Ratings:\", python_ratings)\n",
    "\n",
    "# Applying expert rubric to responses\n",
    "llm_rubric_score, llm_rubric_details = expert_rubric(llm_change_report)\n",
    "python_rubric_score, python_rubric_details = expert_rubric(python_change_report)\n",
    "\n",
    "print(f\"LLM Rubric Score: {llm_rubric_score}\")\n",
    "print(f\"Python Rubric Score: {python_rubric_score}\")\n",
    "print(\"LLM Rubric Details:\", llm_rubric_details)\n",
    "print(\"Python Rubric Details:\", python_rubric_details)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graphql-schema-diff-service",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
